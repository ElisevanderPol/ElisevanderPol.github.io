<!doctype html>
<html lang="">

<head>
	<title>Elise van der Pol </title>
</head>

<body>
	<div>
		<img align="right" src="assets/twitter_foto.jpg" alt="Picture of Elise van der Pol in front of a whiteboard" width="256">
		<h1>Elise van der Pol</h1>
		<h3>PhD student, University of Amsterdam</h3>
	</div>
	<div>
		<ul>
			<li>
				E-mail: e.e.vanderpol[at]uva[dot]nl
			</li>
			<li>
				<a href="https://twitter.com/ElisevanderPol">Twitter</a>
			</li>
			<li>
				<a href="https://scholar.google.nl/citations?hl=en&user=564o-vIAAAAJ">Google Scholar</a>
			</li>
		</ul>
	</div>

	<div>
		<p>I am fascinated by the idea of building agents that use environmental feedback to make better decisions. As a result, my research interests lie in Reinforcement Learning and Machine Learning. I'm a PhD student in the <a href="http://amlab.science.uva.nl">Amsterdam Machine Learning Lab</a>, supervised by Prof. Dr. Max Welling and Dr. Frans Oliehoek (TU Delft). Before my PhD, I studied Artificial Intelligence at the University of Amsterdam where I obtained my Master's degree (cum laude). My MSc thesis was on the subject of <a href="papers/vanderpol_mscthesis.pdf">Deep Reinforcement Learning for Coordinated Traffic Light Controllers</a>. In addition to doing research, I teach practicals and tutorials for courses in the Artificial Intelligence Bachelor's and Master's programmes and supervise research projects and theses for students in these programmes. I am also involved in <a href="https://uva-iai.github.io/">Inclusive AI</a>.</p>
	</div>

	<div>
		<h2>Publications and Preprints</h2>
		<h4>2020</h4>
		<ul>
			<li>
				MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning - <i> E. van der Pol, D.E. Worrall, H. van Hoof, F.A. Oliehoek, M. Welling</> Arxiv Preprint 
				&#183; <a href="https://arxiv.org/abs/2006.16908">PDF</a>
			</li>
			<li>
				Plannable Approximations to MDP Homomorphisms: Equivariance under Actions - <i>E. van der Pol, T. Kipf, F.A. Oliehoek, M. Welling</i>, AAMAS 2020 
				&#183; <a href="http://www.ifaamas.org/Proceedings/aamas2020/pdfs/p1431.pdf">PDF</a> &#183; <a href="https://www.fransoliehoek.net/wp/2020/03/02/plannable-approximations-to-mdp-homomorphisms-equivariance-under-actions/">Description</a> &#183; <a href="https://underline.io/lecture/228-plannable-approximations-to-mdp-homomorphisms-equivariance-under-actions">Video</a> &#183; <a href="https://github.com/ElisevanderPol/PRAE">Code</a>
			</li>
			<li>
				Contrastive Learning of Structured World Models - <i>T. Kipf, E. van der Pol, M. Welling</i>, ICLR 2020 (Oral) 
				&#183; <a href="https://arxiv.org/abs/1911.12247">PDF</a> &#183; <a href="https://iclr.cc/virtual/poster_H1gax6VtDB.html">Video</a> &#183; <a href="https://github.com/tkipf/c-swm">Code</a>
			</li>
		</ul>
		<h4>2019</h4>
		<ul>
			<li>
				Hyperspherical Prototype Networks - <i>P. Mettes, E. van der Pol, C.G.M. Snoek</i>, NeurIPS 2019
				&#183; <a href="http://papers.nips.cc/paper/8428-hyperspherical-prototype-networks">PDF</a> &#183; <a href="https://github.com/psmmettes/hpn">Code</a>
			</li>
		</ul>
		<h4>2018</h4>
		<ul>
			<li>
				Beyond Local Nash Equilibria for Adversarial Networks - <i>F.A. Oliehoek, R. Savani, J. Gallego-Posada, E. van der Pol, R. Gro&szlig;</i>, Benelearn 2018
				&#183; <a href="https://arxiv.org/abs/1806.07268">PDF</a>
			</li>
			<li>
				Visual Rationalizations in Deep Reinforcement Learning for Atari Games - <i>L. Weitkamp, E. van der Pol, Z. Akata</i>, BNAIC 2018 (Oral)
				&#183; <a href="https://arxiv.org/abs/1902.00566">PDF</a>
			</li>
		</ul>
		<h4>2017</h4>
		<ul>
			<li>
				GANGs: Generative Adversarial Network Games - <i>F.A. Oliehoek, R. Savani, J. Gallego-Posada, E. van der Pol, E.D. de Jong, R. Gro&szlig;</i>, Arxiv Preprint
				&#183; <a href="https://arxiv.org/abs/1712.00679">PDF</a>
		</ul>
		<h4>2016</h4>
		<ul>
			<li>
				Deep Reinforcement Learning for Coordination in Traffic Light Control - <i>E. van der Pol, Master's Thesis</i>, University of Amsterdam
				&#183; <a href="papers/vanderpolTHESIS2016.pdf">PDF</a>
			</li>
			<li>
				Coordinated Deep Reinforcement Learners for Traffic Light Control - <i>E. van der Pol, F.A. Oliehoek</i>, NIPS 2016 Workshop on Learning, Inference and Control of Multi-Agent Systems
				&#183; <a href="papers/vanderpolNIPSMALIC2016.pdf">PDF</a>
			</li>
			<li>
				Video Demo: Deep Reinforcement Learning for Coordination in Traffic Light Control - <i>E. van der Pol, F.A. Oliehoek</i>, BNAIC 2016
				&#183; <a href="papers/vanderpolBNAIC2016b.pdf">PDF</a> &#183; <a href="http://www.fransoliehoek.net/trafficvideo">Video</a>
			</li>
			<li>
				Linguistic Style Accommodation in Disagreements - <i>E. van der Pol, S. Gieske, R. Fern&aacute;ndez</i>, *SEM 2016
				&#183; <a href="papers/vanderpolStarSEM2016.pdf">PDF</a>
			</li>
		</ul>

		<h4>2015</h4>
		<ul>
			<li>
				Empirical Evaluation of Collective Rationality for Quota Rules in Judgment Aggregation - <i>S. Gieske, E. van der Pol, U. Endriss</i>, BNAIC 2015
				&#183; <a href="papers/gieskeBNAIC2015.pdf">PDF</a>
			</li>
		</ul>
	</div>


<!--
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-85873403-2', 'auto');
    ga('send', 'pageview');

</script>
-->

</body>

</html>
